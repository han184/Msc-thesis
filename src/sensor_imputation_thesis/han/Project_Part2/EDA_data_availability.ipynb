{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe for Data availability regarding SFOC-relevant sensor (2022-2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of paths\n",
    "paths_new = [\n",
    "    \"/home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/han/dataframe_data_availability_202204\",\n",
    "    \"/home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/han/dataframe_data_availability_202210\",\n",
    "    \"/home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/han/dataframe_data_availability_202304\",\n",
    "    \"/home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/han/dataframe_data_availability_202310\",\n",
    "    \"/home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/han/dataframe_data_availability_202404\",\n",
    "]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results_new = []\n",
    "\n",
    "# Loop through each path, read the parquet file, and calculate the required values\n",
    "for path in paths_new:\n",
    "    data_availability = pd.read_parquet(path)\n",
    "    \n",
    "    # Extract substring from the last letter to index 32\n",
    "    filename = path[-6:]\n",
    "    \n",
    "    # Calculate the percentage of engines with time-series data\n",
    "    percentage_engines = len(data_availability) / 759 * 100\n",
    "    \n",
    "    # Calculate mean and std for each column except 'product_id' and 'time'\n",
    "    mean_values = data_availability.drop(columns=['product_id', 'engine_type', 'time']).mean()\n",
    "    std_values = data_availability.drop(columns=['product_id', 'engine_type', 'time']).std()\n",
    "    \n",
    "    # Create a dictionary to store the results for the current file\n",
    "    result = {\n",
    "        'time': filename,\n",
    "        'percentage_engines': percentage_engines\n",
    "    }\n",
    "\n",
    "    # Add mean and std values to the result dictionary\n",
    "    for column in mean_values.index:\n",
    "        result[f'mean_{column}'] = mean_values[column]\n",
    "        result[f'std_{column}'] = std_values[column]\n",
    "    \n",
    "    # Append the result dictionary to the results list\n",
    "    results_new.append(result)\n",
    "\n",
    "# Convert the results list to a DataFrame\n",
    "results_df_new = pd.DataFrame(results_new)\n",
    "\n",
    "# Print the results DataFrame\n",
    "results_df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the results\n",
    "engine_type_availability_new = []\n",
    "\n",
    "# Loop through each path, read the parquet file, and calculate the required values\n",
    "for path in paths_new:\n",
    "    data_availability = pd.read_parquet(path)\n",
    "\n",
    "    # Extract substring from the last letter to index 32\n",
    "    filename = path[-6:]\n",
    "\n",
    "    # Group by engine type and calculate availability for each sensor data column\n",
    "    sensor_data_columns = [col for col in data_availability.columns if col not in ['product_id', 'engine_type', 'time']]\n",
    "\n",
    "    for engine_type, group in data_availability.groupby('engine_type'):\n",
    "        sensor_data_availability = group[sensor_data_columns].mean()\n",
    "        # Create a dictionary to store the results for the current file and engine type\n",
    "        result = {\n",
    "            'time': filename,\n",
    "            'engine_type': engine_type,\n",
    "            }\n",
    "        # Add sensor data availability as separate columns\n",
    "        for column in sensor_data_columns:\n",
    "            result[column] = sensor_data_availability[column]\n",
    "        # Append the result dictionary to the engine type availability list\n",
    "        engine_type_availability_new.append(result)\n",
    "\n",
    "# Convert the engine type availability list to a DataFrame\n",
    "engine_type_availability_df_new = pd.DataFrame(engine_type_availability_new)\n",
    "\n",
    "# Print the engine type availability DataFrame\n",
    "engine_type_availability_df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data availability by engine type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define regex patterns for each dimension\n",
    "patterns = {\n",
    "    'stroke_bore_ratio': r'(G|S|L|K)',\n",
    "    'piston_diameter_cm': r'(\\d{2})',\n",
    "    'engine_concept': r'(ME-C|ME-B|MC-C)',\n",
    "    'mark': r'(\\d{1,2}\\.)',\n",
    "    'dot_number': r'(\\.\\d+)',\n",
    "    'fuel_injection_concept': r'-(LGIM|LGIP|LGIA|GIE|GI|GA)(?:-[A-Z]+)?',\n",
    "    'emission_reduction': r'-(LPSCR|HPSCR|EGRBP|EGRTC|EcoEGR|TII|W)(?:-[A-Z]+)?'\n",
    "}\n",
    "\n",
    "\n",
    "# Function to extract dimensions from engine_type\n",
    "def extract_dimensions(engine_type):\n",
    "    dimensions = {}\n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, engine_type)\n",
    "        if match:\n",
    "            dimensions[key] = match.group(1)\n",
    "        else:\n",
    "            dimensions[key] = None\n",
    "    return dimensions\n",
    "\n",
    "\n",
    "# Apply the function to extract dimensions and create new columns in the DataFrame\n",
    "dimensions_df = engine_type_availability_df_new['engine_type'].apply(extract_dimensions).apply(pd.Series)\n",
    "\n",
    "# Create a new DataFrame for each dimension and calculate the average availability\n",
    "dimension_dfs = {}\n",
    "for dimension in patterns.keys():\n",
    "    temp_df = pd.concat([engine_type_availability_df_new[['time']], dimensions_df[[dimension]], engine_type_availability_df_new[['te_exh_cyl_out__0', 'te_exh_cyl_out__1',\n",
    "       'te_exh_cyl_out__2', 'te_exh_cyl_out__3', 'te_exh_cyl_out__4',\n",
    "       'te_exh_cyl_out__5', 'te_exh_cyl_out__6', 'pd_air_ic__0',\n",
    "       'pr_exh_turb_out__0', 'pr_exh_turb_out__1', 'pr_exh_turb_out__2',\n",
    "       'pr_exh_turb_out__3', 'te_air_ic_out__0', 'te_air_ic_out__1',\n",
    "       'te_air_ic_out__2', 'te_air_ic_out__3', 'te_seawater',\n",
    "       'te_air_comp_in_a__0', 'te_air_comp_in_a__1', 'te_air_comp_in_a__2',\n",
    "       'te_air_comp_in_a__3', 'te_air_comp_in_b__0', 'te_air_comp_in_b__1',\n",
    "       'te_air_comp_in_b__2', 'te_air_comp_in_b__3', 'fr_tc__0', 'fr_tc__1',\n",
    "       'fr_tc__2', 'fr_tc__3', 'pr_baro', 'pr_exh_rec', 'pr_air_scav_ecs', 'te_air_scav_rec', 'te_exh_turb_in__0', 'te_exh_turb_in__1', 'te_exh_turb_in__2', 'te_exh_turb_in__3', 're_eng_load', 'bo_aux_blower_running', 'in_engine_running_mode']]], axis=1)\n",
    "    grouped_df = temp_df.groupby(['time', dimension]).mean().reset_index()\n",
    "    dimension_dfs[dimension] = grouped_df\n",
    "\n",
    "# Print the resulting DataFrames for each dimension\n",
    "for dimension, df in dimension_dfs.items():\n",
    "    print(f\"DataFrame for {dimension}:\")\n",
    "    print(df)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data availability by engine and by sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data availability results using seaborn and matplotlib\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Manually average the mean for some sensor columns belonging to the same sensor type\n",
    "sensor_groups_mean = {\n",
    "    'Scavenge air receiver temperature': ['mean_te_air_scav_rec'],\n",
    "    'Turbine back pressure': ['mean_pr_exh_turb_out__0', 'mean_pr_exh_turb_out__1', 'mean_pr_exh_turb_out__2', 'mean_pr_exh_turb_out__3'],\n",
    "    'Exhaust gas temperature at turbine inlet': ['mean_te_exh_turb_in__0', 'mean_te_exh_turb_in__1', 'mean_te_exh_turb_in__2', 'mean_te_exh_turb_in__3'],\n",
    "    'TC air intake temperature, sensor 1': ['mean_te_air_comp_in_a__0', 'mean_te_air_comp_in_a__1', 'mean_te_air_comp_in_a__2', 'mean_te_air_comp_in_a__3'],\n",
    "    'Engine room ambient pressure': ['mean_pr_baro'],\n",
    "    'dP air across scavenge air cooler': ['mean_pd_air_ic__0'],\n",
    "    'Exhaust gas receiver pressure': ['mean_pr_exh_rec'],\n",
    "    'ECS, scavenging air receiver pressure': ['mean_pr_air_scav_ecs'],\n",
    "    'PMI, estimated engine load': ['mean_re_eng_load'],\n",
    "    'Seawater temperature': ['mean_te_seawater'],     \n",
    "    'Blower running': ['mean_bo_aux_blower_running'],\n",
    "    'Active engine running mode': ['mean_in_engine_running_mode'],\n",
    "    }\n",
    "for sensor_type, sensors in sensor_groups_mean.items():\n",
    "    results_df_new[f'mean_{sensor_type}'] = results_df_new[sensors].mean(axis=1)\n",
    "\n",
    "# Create a new DataFrame named results_bysensor to include filename, percentage_engines, and average availability for each sensor type\n",
    "results_meanbysensor = results_df_new[['time', 'percentage_engines'] + [f'mean_{sensor_type}' for sensor_type in sensor_groups_mean.keys()]]\n",
    "\n",
    "# Plot mean values for each sensor type for each file\n",
    "mean_columns = [col for col in results_meanbysensor.columns if col.startswith('mean_')]\n",
    "mean_df = results_meanbysensor[['time'] + mean_columns].melt(id_vars='time', var_name='sensor_data_column', value_name='mean_value')\n",
    "\n",
    "\n",
    "# Plot percentage of engines with time-series data for each file\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x='time', y='percentage_engines', data=results_meanbysensor)\n",
    "plt.title('Percentage of Engines with Available Time-Series Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Percentage of Engines(%)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='time', y='mean_value', hue='sensor_data_column', palette='Paired', data=mean_df)\n",
    "plt.title('Average Missing Data Rate Per Sensor (2022-2024)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Average Missing Data Rate Per Sensor (%)')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually average the std for some sensor columns belonging to the same sensor type\n",
    "sensor_groups_std = {\n",
    "    'Scavenge air receiver temperature': ['std_te_air_scav_rec'],\n",
    "    'Turbine back pressure': ['std_pr_exh_turb_out__0', 'std_pr_exh_turb_out__1', 'std_pr_exh_turb_out__2', 'std_pr_exh_turb_out__3'],\n",
    "    'Exhaust gas temperature at turbine inlet': ['std_te_exh_turb_in__0', 'std_te_exh_turb_in__1', 'std_te_exh_turb_in__2', 'std_te_exh_turb_in__3'],\n",
    "    'TC air intake temperature, sensor 1': ['std_te_air_comp_in_a__0', 'std_te_air_comp_in_a__1', 'std_te_air_comp_in_a__2', 'std_te_air_comp_in_a__3'],\n",
    "    'Engine room ambient pressure': ['std_pr_baro'],\n",
    "    'dP air across scavenge air cooler': ['std_pd_air_ic__0'],\n",
    "    'Exhaust gas receiver pressure': ['std_pr_exh_rec'],\n",
    "    'ECS, scavenging air receiver pressure': ['std_pr_air_scav_ecs'],\n",
    "    'PMI, estimated engine load': ['std_re_eng_load'],\n",
    "    'Seawater temperature': ['std_te_seawater'],     \n",
    "    'Blower running': ['std_bo_aux_blower_running'],\n",
    "    'Active engine running mode': ['std_in_engine_running_mode'],\n",
    "    }\n",
    "\n",
    "for sensor_type, sensors in sensor_groups_std.items():\n",
    "    results_df_new[f'std_{sensor_type}'] = results_df_new[sensors].mean(axis=1)\n",
    "\n",
    "# Create a new DataFrame named results_bysensor to include filename, percentage_engines, and average availability for each sensor type\n",
    "results_std_bysensor = results_df_new[['time', 'percentage_engines'] + [f'std_{sensor_type}' for sensor_type in sensor_groups_std.keys()]]\n",
    "\n",
    "\n",
    "# Plot std values for each sensor data column for each file\\n\",\n",
    "std_columns = [col for col in results_std_bysensor.columns if col.startswith('std_')]\n",
    "std_df = results_std_bysensor[['time'] + std_columns].melt(id_vars='time', var_name='sensor_data_column', value_name='std_value')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='time', y='std_value', hue='sensor_data_column', palette='Paired', data=std_df)\n",
    "plt.title('Sensor Data Missing Rate Variability (2022â€“2024)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Standard Deviation of Missing Data Per Sensor')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
