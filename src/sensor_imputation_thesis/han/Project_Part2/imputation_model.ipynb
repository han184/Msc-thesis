{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tabpfn import TabPFNRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/han/dataframe_tabpfn5\"\n",
    "df = pd.read_parquet(path)\n",
    "\n",
    "# filter once outside columns loop since condition is independent of target column\n",
    "filtered_df = df[(df['fr_eng'] > (10/60))]\n",
    "filtered_df = filtered_df.sort_values(by='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Choose a variable as y and other variables as X\n",
    "target_column_list = ['te_air_scav_rec', 'pr_baro', 'pd_air_ic__0', 'pr_exh_rec', 'pr_air_scav_ecs', 're_eng_load']\n",
    "column_dfs = []\n",
    "\n",
    "for column in target_column_list:\n",
    "    \n",
    "\n",
    "    # Drop rows with NaN target value\n",
    "    if column not in filtered_df.columns:\n",
    "        print(f\"  Skipping {column} in current df: column missing.\")\n",
    "        continue\n",
    "\n",
    "    df_col = filtered_df.dropna(subset=[column])\n",
    "    if df_col.empty:\n",
    "        print(f\"  Skipping {column} in current df: no data after dropna.\")\n",
    "        continue\n",
    "\n",
    "    column_dfs.append(df_col)\n",
    "\n",
    "\n",
    "if not column_dfs:\n",
    "    raise ValueError(\"No valid dataframes to concatenate. Check filtering conditions or target columns.\")\n",
    "    \n",
    "combined_df = pd.concat(column_dfs, ignore_index=True)\n",
    "df_length = len(combined_df)\n",
    "\n",
    "# Train-test split\n",
    "train_df = combined_df.iloc[:int(df_length * 0.8)]\n",
    "test_df = combined_df.iloc[int(df_length * 0.8):]\n",
    "\n",
    "# Drop non-numeric columns\n",
    "numeric_cols = train_df.select_dtypes(include='number').columns\n",
    "numeric_cols = [col for col in numeric_cols if train_df[col].notnull().any()]\n",
    "\n",
    "train_numeric = train_df[numeric_cols]\n",
    "test_numeric = test_df[numeric_cols]\n",
    "test_copy = test_numeric.copy()\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputer.fit(train_numeric)\n",
    "\n",
    "test_imputed_numeric = pd.DataFrame(\n",
    "    imputer.transform(test_copy),\n",
    "    columns=train_numeric.columns,\n",
    "    index=test_copy.index\n",
    ")\n",
    "\n",
    "# Evaluate R² for each target column\n",
    "for column in target_column_list:\n",
    "    print(f\"\\n==== Processing target column: {column} ====\")\n",
    "    if column not in train_numeric.columns:\n",
    "        print(f\"Skipping {column}: not numeric or no non-missing values in train\")\n",
    "        continue\n",
    "\n",
    "    non_missing_idx = test_copy[test_copy[column].notnull()].index\n",
    "    mask_size = min(20, len(non_missing_idx))\n",
    "    mask_idx = np.random.choice(non_missing_idx, size=mask_size, replace=False)\n",
    "\n",
    "    true_values = test_copy.loc[mask_idx, column].copy()\n",
    "    test_copy.loc[mask_idx, column] = np.nan\n",
    "\n",
    "    # Impute again for evaluation\n",
    "    test_imputed_numeric = pd.DataFrame(\n",
    "        imputer.transform(test_copy),\n",
    "        columns=train_numeric.columns,\n",
    "        index=test_copy.index\n",
    "    )\n",
    "\n",
    "    imputed_values = test_imputed_numeric.loc[mask_idx, column]\n",
    "\n",
    "    # Compute R²\n",
    "    r2 = r2_score(true_values, imputed_values)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(true_values, imputed_values)\n",
    "    mae = mean_absolute_error(true_values, imputed_values)\n",
    "\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"R² Score:\", r2)\n",
    "\n",
    "    # Create figure and axes\n",
    "    fig = plt.figure(figsize=(8, 10))\n",
    "    grid = plt.GridSpec(4, 4, hspace=0.5, wspace=0.5)\n",
    "\n",
    "    main_ax = fig.add_subplot(grid[1:4, 0:3])\n",
    "    x_hist = fig.add_subplot(grid[0, 0:3], sharex=main_ax)\n",
    "    y_hist = fig.add_subplot(grid[1:4, 3], sharey=main_ax)\n",
    "\n",
    "    # Scatter plot with R²\n",
    "    main_ax.scatter(true_values, imputed_values, alpha=0.6)\n",
    "    main_ax.set_xlabel('Original Data')\n",
    "    main_ax.set_ylabel('Predicted Data')\n",
    "    main_ax.set_title(f'R² Plot (R² = {r2:.2f})')\n",
    "\n",
    "    # Add y = x line\n",
    "    min_val = min(min(true_values), min(imputed_values))\n",
    "    max_val = max(max(true_values), max(imputed_values))\n",
    "    main_ax.plot([min_val, max_val], [min_val, max_val], 'r--', label='y = x')\n",
    "    main_ax.legend()\n",
    "\n",
    "    # Histograms\n",
    "    x_hist.hist(true_values, bins=20, alpha=0.7)\n",
    "\n",
    "    y_hist.hist(imputed_values, bins=20, orientation='horizontal', alpha=0.7)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "df = filtered_df.copy()\n",
    "df = df.sort_values(by='time')\n",
    "\n",
    "# Collect all valid rows for each target column\n",
    "column_dfs = []\n",
    "for column in target_column_list:\n",
    "    if column not in df.columns:\n",
    "        print(f\"Skipping {column}: column missing\")\n",
    "        continue\n",
    "    df_col = df.dropna(subset=[column])  # drop rows where target is NaN\n",
    "    if df_col.empty:\n",
    "        print(f\"Skipping {column}: no data after dropna\")\n",
    "        continue\n",
    "    column_dfs.append(df_col)\n",
    "\n",
    "if not column_dfs:\n",
    "    raise ValueError(\"No valid dataframes to concatenate.\")\n",
    "\n",
    "combined_df = pd.concat(column_dfs, ignore_index=True)\n",
    "\n",
    "# === Train-test split ===\n",
    "df_length = len(combined_df)\n",
    "train_df = combined_df.iloc[:int(df_length * 0.8)].copy()\n",
    "test_df = combined_df.iloc[int(df_length * 0.8):].copy()\n",
    "\n",
    "# === Numeric columns only, drop 'time' if present ===\n",
    "numeric_cols = train_df.select_dtypes(include='number').columns\n",
    "numeric_cols = [col for col in numeric_cols if col != 'time']\n",
    "\n",
    "# Drop columns that are entirely NaN\n",
    "train_numeric = train_numeric.dropna(axis=1, how=\"all\")\n",
    "test_numeric = test_numeric[train_numeric.columns]\n",
    "\n",
    "# === Apply KNN imputer ===\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "train_imputed = pd.DataFrame(\n",
    "    imputer.fit_transform(train_numeric),\n",
    "    columns=train_numeric.columns,\n",
    "    index=train_numeric.index\n",
    ")\n",
    "\n",
    "test_imputed = pd.DataFrame(\n",
    "    imputer.transform(test_numeric),\n",
    "    columns=test_numeric.columns,\n",
    "    index=test_numeric.index\n",
    ")\n",
    "\n",
    "# === Linear Regression for each target column ===\n",
    "for column in target_column_list:\n",
    "    if column not in train_imputed.columns:\n",
    "        print(f\"Skipping {column}: not numeric or dropped\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n==== Linear Regression for target: {column} ====\")\n",
    "\n",
    "    # Features and target\n",
    "    X_train = train_imputed.drop(columns=[column])\n",
    "    y_train = train_imputed[column]\n",
    "\n",
    "    X_test = test_imputed.drop(columns=[column])\n",
    "    y_test = test_imputed[column]\n",
    "\n",
    "    # Fit model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate R² score\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"R² Score:\", r2)\n",
    "\n",
    "    # Create figure and axes\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    grid = plt.GridSpec(4, 4, hspace=0.5, wspace=0.5)\n",
    "\n",
    "    main_ax = fig.add_subplot(grid[1:4, 0:3])\n",
    "    x_hist = fig.add_subplot(grid[0, 0:3], sharex=main_ax)\n",
    "    y_hist = fig.add_subplot(grid[1:4, 3], sharey=main_ax)\n",
    "\n",
    "    # Scatter plot with R²\n",
    "    main_ax.scatter(y_test, predictions, alpha=0.6)\n",
    "    main_ax.set_xlabel('Original Data')\n",
    "    main_ax.set_ylabel('Predicted Data')\n",
    "    main_ax.set_title(f'R² Plot (R² = {r2:.2f})')\n",
    "\n",
    "    # Add y = x line\n",
    "    min_val = min(min(y_test), min(predictions))\n",
    "    max_val = max(max(y_test), max(predictions))\n",
    "    main_ax.plot([min_val, max_val], [min_val, max_val], 'r--', label='y = x')\n",
    "    main_ax.legend()\n",
    "\n",
    "    # Histograms\n",
    "    x_hist.hist(y_test, bins=20, alpha=0.7)\n",
    "\n",
    "    y_hist.hist(predictions, bins=20, orientation='horizontal', alpha=0.7)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "df = filtered_df.copy()\n",
    "df = df.sort_values(by='time')\n",
    "\n",
    "# Collect all valid rows for each target column\n",
    "column_dfs = []\n",
    "for column in target_column_list:\n",
    "    if column not in df.columns:\n",
    "        print(f\"Skipping {column}: column missing\")\n",
    "        continue\n",
    "    df_col = df.dropna(subset=[column])  # drop rows where target is NaN\n",
    "    if df_col.empty:\n",
    "        print(f\"Skipping {column}: no data after dropna\")\n",
    "        continue\n",
    "    column_dfs.append(df_col)\n",
    "\n",
    "if not column_dfs:\n",
    "    raise ValueError(\"No valid dataframes to concatenate.\")\n",
    "\n",
    "combined_df = pd.concat(column_dfs, ignore_index=True)\n",
    "\n",
    "# === Train-test split ===\n",
    "df_length = len(combined_df)\n",
    "train_df = combined_df.iloc[:int(df_length * 0.8)].copy()\n",
    "test_df = combined_df.iloc[int(df_length * 0.8):].copy()\n",
    "\n",
    "# === Numeric columns only, drop 'time' if present ===\n",
    "numeric_cols = train_df.select_dtypes(include='number').columns\n",
    "numeric_cols = [col for col in numeric_cols if col != 'time']\n",
    "\n",
    "train_numeric = train_df[numeric_cols].copy()\n",
    "test_numeric = test_df[numeric_cols].copy()\n",
    "\n",
    "# Drop columns that are entirely NaN\n",
    "train_numeric = train_numeric.dropna(axis=1, how=\"all\")\n",
    "test_numeric = test_numeric[train_numeric.columns]  # align columns\n",
    "\n",
    "# === Apply KNN imputer ===\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "train_imputed = pd.DataFrame(\n",
    "    imputer.fit_transform(train_numeric),\n",
    "    columns=train_numeric.columns,\n",
    "    index=train_numeric.index\n",
    ")\n",
    "\n",
    "test_imputed = pd.DataFrame(\n",
    "    imputer.transform(test_numeric),\n",
    "    columns=test_numeric.columns,\n",
    "    index=test_numeric.index\n",
    ")\n",
    "\n",
    "# === Random Forest for each target column ===\n",
    "for column in target_column_list:\n",
    "    if column not in train_imputed.columns:\n",
    "        print(f\"Skipping {column}: not numeric or dropped\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n==== Random Forest for target: {column} ====\")\n",
    "\n",
    "    # Features and target\n",
    "    X_train = train_imputed.drop(columns=[column])\n",
    "    y_train = train_imputed[column]\n",
    "\n",
    "    X_test = test_imputed.drop(columns=[column])\n",
    "    y_test = test_imputed[column]\n",
    "\n",
    "    # Fit model\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100, \n",
    "        random_state=42, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate R² score\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"R² Score:\", r2)\n",
    "\n",
    "    # Create figure and axes\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    grid = plt.GridSpec(4, 4, hspace=0.5, wspace=0.5)\n",
    "\n",
    "    main_ax = fig.add_subplot(grid[1:4, 0:3])\n",
    "    x_hist = fig.add_subplot(grid[0, 0:3], sharex=main_ax)\n",
    "    y_hist = fig.add_subplot(grid[1:4, 3], sharey=main_ax)\n",
    "\n",
    "    # Scatter plot with R²\n",
    "    main_ax.scatter(y_test, predictions, alpha=0.6)\n",
    "    main_ax.set_xlabel('Original Data')\n",
    "    main_ax.set_ylabel('Predicted Data')\n",
    "    main_ax.set_title(f'R² Plot (R² = {r2:.2f})')\n",
    "\n",
    "    # Add y = x line\n",
    "    min_val = min(min(y_test), min(predictions))\n",
    "    max_val = max(max(y_test), max(predictions))\n",
    "    main_ax.plot([min_val, max_val], [min_val, max_val], 'r--', label='y = x')\n",
    "    main_ax.legend()\n",
    "\n",
    "    # Histograms\n",
    "    x_hist.hist(y_test, bins=20, alpha=0.7)\n",
    "\n",
    "    y_hist.hist(predictions, bins=20, orientation='horizontal', alpha=0.7)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tabPFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a variable as y and other variables as X\n",
    "target_column_list = ['te_air_scav_rec', 'pr_baro', 'pd_air_ic__0', 'pr_exh_rec', 'pr_air_scav_ecs', 're_eng_load', 'te_seawater', 'bo_aux_blower_running', 'IN_ENGINE_RUNNING_MODE']\n",
    "\n",
    "for column in target_column_list:\n",
    "    print(f\"\\n==== Processing target column: {column} ====\")\n",
    "    column_dfs = []\n",
    "    \n",
    "    # filter once outside columns loop since condition is independent of target column\n",
    "    filtered_df = df[(df['fr_eng'] > (10/60))]\n",
    "    filtered_df = filtered_df.iloc[:, filtered_df.nunique().values > 1]\n",
    "    filtered_df = filtered_df.iloc[:, filtered_df.isna().mean().values < 0.95]\n",
    "    filtered_df = filtered_df.sort_values(by='time')\n",
    "\n",
    "    # Drop rows with NaN target value\n",
    "    if column not in filtered_df.columns:\n",
    "        print(f\"  Skipping {column} in current df: column missing.\")\n",
    "        continue\n",
    "\n",
    "    df_col = filtered_df.dropna(subset=[column])\n",
    "    if df_col.empty:\n",
    "        print(f\"  Skipping {column} in current df: no data after dropna.\")\n",
    "        continue\n",
    "\n",
    "    column_dfs.append(df_col)\n",
    "\n",
    "\n",
    "    if not column_dfs:\n",
    "        raise ValueError(\"No valid dataframes to concatenate. Check filtering conditions or target columns.\")\n",
    "    combined_df = pd.concat(column_dfs, ignore_index=True)\n",
    "    df_length = len(combined_df)\n",
    "\n",
    "    # Train-test split\n",
    "    train_df = combined_df.iloc[:int(df_length * 0.8)]\n",
    "    test_df = combined_df.iloc[int(df_length * 0.8):]\n",
    "\n",
    "    # Sample (cap at max size)\n",
    "    train_sample_size = min(len(train_df), 10000)\n",
    "    test_sample_size = min(len(test_df), 2500)\n",
    "\n",
    "    train_sampled = train_df.sample(n=train_sample_size, random_state=42).dropna(subset=[column])\n",
    "    test_sampled = test_df.sample(n=test_sample_size, random_state=42).dropna(subset=[column])\n",
    "\n",
    "    print(f\"Training size for {column}:\", len(train_sampled))\n",
    "    print(f\"Testing size for {column}:\", len(test_sampled))\n",
    "\n",
    "    X_train = train_sampled.drop(columns=[column, 'time'])\n",
    "    y_train = train_sampled[column]\n",
    "    X_test = test_sampled.drop(columns=[column, 'time'])\n",
    "    y_test = test_sampled[column]\n",
    "\n",
    "    # Initialize and train regressor\n",
    "    regressor = TabPFNRegressor()\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    predictions = regressor.predict(X_test)\n",
    "\n",
    "    # Calculate R² score\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"R² Score:\", r2)\n",
    "\n",
    "    # Create figure and axes\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    grid = plt.GridSpec(4, 4, hspace=0.5, wspace=0.5)\n",
    "\n",
    "    main_ax = fig.add_subplot(grid[1:4, 0:3])\n",
    "    x_hist = fig.add_subplot(grid[0, 0:3], sharex=main_ax)\n",
    "    y_hist = fig.add_subplot(grid[1:4, 3], sharey=main_ax)\n",
    "\n",
    "    # Scatter plot with R²\n",
    "    main_ax.scatter(y_test, predictions, alpha=0.6)\n",
    "    main_ax.set_xlabel('Original Data')\n",
    "    main_ax.set_ylabel('Predicted Data')\n",
    "    main_ax.set_title(f'R² Plot (R² = {r2:.2f})')\n",
    "\n",
    "    # Add y = x line\n",
    "    min_val = min(min(y_test), min(predictions))\n",
    "    max_val = max(max(y_test), max(predictions))\n",
    "    main_ax.plot([min_val, max_val], [min_val, max_val], 'r--', label='y = x')\n",
    "    main_ax.legend()\n",
    "\n",
    "    # Histograms\n",
    "    x_hist.hist(y_test, bins=20, alpha=0.7)\n",
    "\n",
    "    y_hist.hist(predictions, bins=20, orientation='horizontal', alpha=0.7)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
