{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tabpfn import TabPFNRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/han/dataframe_engine1_2_forimputation\"\n",
    "df = pd.read_parquet(path)\n",
    "\n",
    "# filter once outside columns loop since condition is independent of target column\n",
    "filtered_df = df[(df['fr_eng'] > (10/60))]\n",
    "filtered_df = filtered_df.sort_values(by='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Choose a variable as y and other variables as X\n",
    "target_column_list = ['te_air_scav_rec', 'pr_baro', 'pd_air_ic__0', 'pr_exh_rec', 'pr_air_scav_ecs', 're_eng_load', 'te_seawater']\n",
    "column_dfs = []\n",
    "\n",
    "for column in target_column_list:\n",
    "    # Drop rows with NaN target value\n",
    "    if column not in filtered_df.columns:\n",
    "        print(f\"  Skipping {column} in current df: column missing.\")\n",
    "        continue\n",
    "\n",
    "    df_col = filtered_df.dropna(subset=[column])\n",
    "    if df_col.empty:\n",
    "        print(f\"  Skipping {column} in current df: no data after dropna.\")\n",
    "        continue\n",
    "\n",
    "    column_dfs.append(df_col)\n",
    "\n",
    "\n",
    "if not column_dfs:\n",
    "    raise ValueError(\"No valid dataframes to concatenate. Check filtering conditions or target columns.\")\n",
    "    \n",
    "combined_df = pd.concat(column_dfs, ignore_index=True)\n",
    "df_length = len(combined_df)\n",
    "\n",
    "# Train-test split\n",
    "train_df = combined_df.iloc[:int(df_length * 0.8)]\n",
    "test_df = combined_df.iloc[int(df_length * 0.8):]\n",
    "\n",
    "# Drop non-numeric columns\n",
    "numeric_cols = train_df.select_dtypes(include='number').columns\n",
    "numeric_cols = [col for col in numeric_cols if train_df[col].notnull().any()]\n",
    "\n",
    "train_numeric = train_df[numeric_cols]\n",
    "test_numeric = test_df[numeric_cols].copy()\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputer.fit(train_numeric)\n",
    "\n",
    "\n",
    "# Evaluate R² for each target column\n",
    "for col in target_column_list:\n",
    "    print(f\"\\n==== Processing target column: {col} ====\")\n",
    "    if col not in train_numeric.columns:\n",
    "        print(f\"Skipping {col}: not numeric or no valid values in train\")\n",
    "        continue\n",
    "\n",
    "    # Pick non-missing test values\n",
    "    non_missing_idx = test_numeric[test_numeric[col].notnull()].index\n",
    "    if non_missing_idx.empty:\n",
    "        print(f\"Skipping {col}: no non-missing values in test\")\n",
    "        continue\n",
    "\n",
    "    mask_size = min(20, len(non_missing_idx))\n",
    "    mask_idx = np.random.choice(non_missing_idx, size=mask_size, replace=False)\n",
    "\n",
    "    # Save true values and mask them\n",
    "    true_values = test_numeric.loc[mask_idx, col].copy()\n",
    "    test_numeric.loc[mask_idx, col] = np.nan\n",
    "\n",
    "    # Impute test data\n",
    "    imputed = pd.DataFrame(\n",
    "        imputer.transform(test_numeric),\n",
    "        columns=train_numeric.columns,\n",
    "        index=test_numeric.index\n",
    "    )\n",
    "    imputed_values = imputed.loc[mask_idx, col]\n",
    "    \n",
    "    # Compute R²\n",
    "    r2 = r2_score(true_values, imputed_values)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(true_values, imputed_values)\n",
    "    mae = mean_absolute_error(true_values, imputed_values)\n",
    "\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"R² Score:\", r2)\n",
    "\n",
    "    # Create figure and axes\n",
    "    fig = plt.figure(figsize=(8, 10))\n",
    "    grid = plt.GridSpec(4, 4, hspace=0.5, wspace=0.5)\n",
    "\n",
    "    main_ax = fig.add_subplot(grid[1:4, 0:3])\n",
    "    x_hist = fig.add_subplot(grid[0, 0:3], sharex=main_ax)\n",
    "    y_hist = fig.add_subplot(grid[1:4, 3], sharey=main_ax)\n",
    "\n",
    "    # Scatter plot with R²\n",
    "    main_ax.scatter(true_values, imputed_values, alpha=0.6)\n",
    "    main_ax.set_xlabel('Original Data')\n",
    "    main_ax.set_ylabel('Predicted Data')\n",
    "    main_ax.set_title(f'R² Plot (R² = {r2:.2f})')\n",
    "\n",
    "    # Add y = x line\n",
    "    min_val = min(min(true_values), min(imputed_values))\n",
    "    max_val = max(max(true_values), max(imputed_values))\n",
    "    main_ax.plot([min_val, max_val], [min_val, max_val], 'r--', label='y = x')\n",
    "    main_ax.legend()\n",
    "\n",
    "    # Histograms\n",
    "    x_hist.hist(true_values, bins=20, alpha=0.7)\n",
    "\n",
    "    y_hist.hist(imputed_values, bins=20, orientation='horizontal', alpha=0.7)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "df = filtered_df.copy()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"imputer\", IterativeImputer(max_iter=10, random_state=0)),  # iterative imputation\n",
    "    (\"scaler\", StandardScaler()),                                # standardization\n",
    "    (\"regressor\", LinearRegression())                            # linear regression\n",
    "])\n",
    "\n",
    "for column in target_column_list:\n",
    "    print(f\"\\n==== Processing target column: {column} ====\")\n",
    "    # Drop rows where current target is missing\n",
    "    df_col = df.dropna(subset=[column])\n",
    "    if df_col.empty:\n",
    "        print(f\"Skipping {column}: no data after dropna.\")\n",
    "        continue\n",
    "\n",
    "    # Feature/target split\n",
    "    X = df_col.drop(columns=[column, \"time\"])\n",
    "    y = df_col[column]\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit model\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    predictions = pipe.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"R² Score:\", r2)\n",
    "\n",
    "    # Create figure and axes\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    grid = plt.GridSpec(4, 4, hspace=0.5, wspace=0.5)\n",
    "\n",
    "    main_ax = fig.add_subplot(grid[1:4, 0:3])\n",
    "    x_hist = fig.add_subplot(grid[0, 0:3], sharex=main_ax)\n",
    "    y_hist = fig.add_subplot(grid[1:4, 3], sharey=main_ax)\n",
    "\n",
    "    # Scatter plot with R²\n",
    "    main_ax.scatter(y_test, predictions, alpha=0.6)\n",
    "    main_ax.set_xlabel('Original Data')\n",
    "    main_ax.set_ylabel('Predicted Data')\n",
    "    main_ax.set_title(f'R² Plot (R² = {r2:.2f})')\n",
    "\n",
    "    # Add y = x line\n",
    "    min_val = min(min(y_test), min(predictions))\n",
    "    max_val = max(max(y_test), max(predictions))\n",
    "    main_ax.plot([min_val, max_val], [min_val, max_val], 'r--', label='y = x')\n",
    "    main_ax.legend()\n",
    "\n",
    "    # Histograms\n",
    "    x_hist.hist(y_test, bins=20, alpha=0.7)\n",
    "\n",
    "    y_hist.hist(predictions, bins=20, orientation='horizontal', alpha=0.7)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "df = filtered_df.copy()\n",
    "\n",
    "# Random Forest model\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"imputer\", IterativeImputer(max_iter=10, random_state=0)),  # iterative imputation\n",
    "    (\"scaler\", StandardScaler()),                                # scaling (not strictly needed for RF, but harmless)\n",
    "    (\"regressor\", rf_model)                                      # random forest\n",
    "])\n",
    "\n",
    "for column in target_column_list:\n",
    "    print(f\"\\n==== Processing target column: {column} ====\")\n",
    "    # Drop rows where current target is missing\n",
    "    df_col = df.dropna(subset=[column])\n",
    "    if df_col.empty:\n",
    "        print(f\"Skipping {column}: no data after dropna.\")\n",
    "        continue\n",
    "\n",
    "    # Feature/target split\n",
    "    X = df_col.drop(columns=[column, \"time\"])\n",
    "    y = df_col[column]\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit model\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    predictions = pipe.predict(X_test)\n",
    "\n",
    "    # Calculate R² score\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"R² Score:\", r2)\n",
    "\n",
    "    # Create figure and axes\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    grid = plt.GridSpec(4, 4, hspace=0.5, wspace=0.5)\n",
    "\n",
    "    main_ax = fig.add_subplot(grid[1:4, 0:3])\n",
    "    x_hist = fig.add_subplot(grid[0, 0:3], sharex=main_ax)\n",
    "    y_hist = fig.add_subplot(grid[1:4, 3], sharey=main_ax)\n",
    "\n",
    "    # Scatter plot with R²\n",
    "    main_ax.scatter(y_test, predictions, alpha=0.6)\n",
    "    main_ax.set_xlabel('Original Data')\n",
    "    main_ax.set_ylabel('Predicted Data')\n",
    "    main_ax.set_title(f'R² Plot (R² = {r2:.2f})')\n",
    "\n",
    "    # Add y = x line\n",
    "    min_val = min(min(y_test), min(predictions))\n",
    "    max_val = max(max(y_test), max(predictions))\n",
    "    main_ax.plot([min_val, max_val], [min_val, max_val], 'r--', label='y = x')\n",
    "    main_ax.legend()\n",
    "\n",
    "    # Histograms\n",
    "    x_hist.hist(y_test, bins=20, alpha=0.7)\n",
    "\n",
    "    y_hist.hist(predictions, bins=20, orientation='horizontal', alpha=0.7)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
